/*
========================================================================================
    WES Pipeline Configuration File
========================================================================================
*/

// Global default params
params {
    // Input/Output
    input                    = null
    input_dir                = null
    pattern                  = "*_R{1,2}.fastq.gz"
    outdir                   = "./results"
    
    // Reference genome
    reference                = 'hg38'  // hg38 or hg19
    reference_fasta          = null    // Custom reference FASTA
    reference_dir            = "./reference"
    
    // Target regions
    bed                      = null    // Target BED file (REQUIRED)
    repeat_bed               = null    // Repeat regions BED
    
    // Compute mode
    compute_mode             = 'cpu'   // cpu, gpu, hybrid
    max_gpus                 = 4
    gpu_devices              = null    // null = auto-detect, or "0,1,2,3"
    samples_per_gpu          = 1
    
    // GPU-specific options
    gpu_memory_limit         = 40      // GB per GPU
    cuda_streams             = 8
    parabricks_license       = null
    parabricks_tmp_dir       = '/tmp/parabricks'
    
    // Parallelization
    parallel_chromosomes     = true
    chromosomes_per_gpu      = 'auto'
    chromosome_split_size    = null    // Split large chromosomes (bp)
    
    // BQSR known sites (auto-downloaded if not provided)
    known_sites_dbsnp        = null
    known_sites_mills        = null
    known_sites_1000g        = null
    
    // Trimming options (fastp)
    trim_front1              = 0
    trim_front2              = 0
    trim_tail1               = 0
    trim_tail2               = 0
    min_length               = 36
    cut_mean_quality         = 20
    
    // Alignment options
    bwa_mem2_threads         = 16
    sort_threads             = 8
    markdup_threads          = 8
    
    // Variant calling options
    call_conf                = 30
    emit_ref_confidence      = 'NONE'  // NONE, BP_RESOLUTION, GVCF
    
    // Variant filtering (hard filters)
    snp_filter_qd            = 2.0
    snp_filter_fs            = 60.0
    snp_filter_mq            = 40.0
    snp_filter_mqranksum     = -12.5
    snp_filter_readposranksum = -8.0
    snp_filter_sor           = 3.0
    
    indel_filter_qd          = 2.0
    indel_filter_fs          = 200.0
    indel_filter_readposranksum = -20.0
    indel_filter_sor         = 10.0
    
    // Repeat expansion
    run_expansion_hunter     = true
    variant_catalog          = null    // ExpansionHunter variant catalog
    
    // Resource limits
    max_cpus                 = 64
    max_memory               = '256.GB'
    max_time                 = '240.h'
    
    // Output options
    save_intermediate        = false   // Save intermediate BAMs
    save_reference           = true    // Save downloaded reference
    publish_dir_mode         = 'copy'
    
    // Skip options
    skip_qc                  = false
    skip_multiqc             = false
    skip_hsmetrics           = false
    skip_expansion_hunter    = false
    
    // MultiQC
    multiqc_config           = null
    multiqc_title            = "WES Pipeline Report"
    
    // Help
    help                     = false
    version                  = false
}

/*
========================================================================================
    Process resource defaults
========================================================================================
*/

process {
    // Global defaults
    cpus   = { check_max( 2 * task.attempt, 'cpus' ) }
    memory = { check_max( 8.GB * task.attempt, 'memory' ) }
    time   = { check_max( 4.h * task.attempt, 'time' ) }
    
    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries    = 2
    maxErrors     = '-1'
    
    // Process-specific resources
    withLabel: low_cpu {
        cpus   = { check_max( 2, 'cpus' ) }
        memory = { check_max( 4.GB * task.attempt, 'memory' ) }
        time   = { check_max( 2.h * task.attempt, 'time' ) }
    }
    
    withLabel: medium_cpu {
        cpus   = { check_max( 8 * task.attempt, 'cpus' ) }
        memory = { check_max( 16.GB * task.attempt, 'memory' ) }
        time   = { check_max( 8.h * task.attempt, 'time' ) }
    }
    
    withLabel: high_cpu {
        cpus   = { check_max( 16 * task.attempt, 'cpus' ) }
        memory = { check_max( 32.GB * task.attempt, 'memory' ) }
        time   = { check_max( 16.h * task.attempt, 'time' ) }
    }
    
    withLabel: very_high_cpu {
        cpus   = { check_max( 32 * task.attempt, 'cpus' ) }
        memory = { check_max( 64.GB * task.attempt, 'memory' ) }
        time   = { check_max( 24.h * task.attempt, 'time' ) }
    }
    
    withLabel: gpu_process {
        cpus   = { check_max( 16, 'cpus' ) }
        memory = { check_max( 64.GB * task.attempt, 'memory' ) }
        time   = { check_max( 12.h * task.attempt, 'time' ) }
        containerOptions = '--gpus all'
    }
    
    withLabel: gpu_variant_calling {
        cpus   = { check_max( 8, 'cpus' ) }
        memory = { check_max( 32.GB * task.attempt, 'memory' ) }
        time   = { check_max( 6.h * task.attempt, 'time' ) }
        containerOptions = '--gpus all'
    }
}

/*
========================================================================================
    Execution profiles
========================================================================================
*/

profiles {
    // Standard CPU execution
    standard {
        params.compute_mode = 'cpu'
        docker.enabled = true
        docker.userEmulation = true
        docker.runOptions = '-u $(id -u):$(id -g)'
    }
    
    // Single GPU
    gpu_single {
        params.compute_mode = 'gpu'
        params.max_gpus = 1
        docker.enabled = true
        docker.runOptions = '--gpus all -u $(id -u):$(id -g)'
    }
    
    // Multi-GPU
    gpu_multi {
        params.compute_mode = 'gpu'
        params.max_gpus = 4
        params.samples_per_gpu = 2
        docker.enabled = true
        docker.runOptions = '--gpus all -u $(id -u):$(id -g)'
    }
    
    // Hybrid mode (recommended)
    hybrid {
        params.compute_mode = 'hybrid'
        params.max_gpus = 2
        docker.enabled = true
        docker.runOptions = '--gpus all -u $(id -u):$(id -g)'
    }
    
    // GPU extreme performance
    gpu_extreme {
        params.compute_mode = 'gpu'
        params.max_gpus = 8
        params.samples_per_gpu = 4
        params.parallel_chromosomes = true
        params.chromosome_split_size = 10000000
        docker.enabled = true
        docker.runOptions = '--gpus all -u $(id -u):$(id -g)'
    }
    
    // Singularity
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        params.compute_mode = 'cpu'
    }
    
    // Singularity with GPU
    singularity_gpu {
        singularity.enabled = true
        singularity.autoMounts = true
        singularity.runOptions = '--nv'
        params.compute_mode = 'gpu'
    }
    
    // Local execution
    local {
        executor {
            name = 'local'
            cpus = params.max_cpus
            memory = params.max_memory
        }
    }
    
    // HPC with SLURM
    slurm {
        process.executor = 'slurm'
        process.queue = 'compute'
        process.clusterOptions = '--account=your_account'
    }
    
    // Cloud - AWS Batch
    awsbatch {
        process.executor = 'awsbatch'
        process.queue = 'your-queue'
        aws.region = 'us-east-1'
        aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
    }
    
    // Testing
    test {
        params.max_cpus = 4
        params.max_memory = '16.GB'
        params.max_time = '2.h'
    }
}

/*
========================================================================================
    Container settings
========================================================================================
*/

docker {
    enabled = false
    userEmulation = true
    temp = 'auto'
}

singularity {
    enabled = false
    autoMounts = true
    cacheDir = "${HOME}/.singularity/cache"
}

/*
========================================================================================
    Resource limit functions
========================================================================================
*/

def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

/*
========================================================================================
    Manifest
========================================================================================
*/

manifest {
    name            = 'wes-pipeline'
    author          = 'Your Organization'
    homePage        = 'https://github.com/your-org/wes-pipeline'
    description     = 'Ultra-fast Whole Exome Sequencing Pipeline with GPU support'
    mainScript      = 'main.nf'
    nextflowVersion = '>=23.04.0'
    version         = '1.0.0'
}

/*
========================================================================================
    Reporting
========================================================================================
*/

timeline {
    enabled = true
    file    = "${params.outdir}/reports/execution_timeline.html"
}

report {
    enabled = true
    file    = "${params.outdir}/reports/execution_report.html"
}

trace {
    enabled = true
    file    = "${params.outdir}/reports/execution_trace.txt"
    fields  = 'task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes'
}

dag {
    enabled = true
    file    = "${params.outdir}/reports/pipeline_dag.html"
}